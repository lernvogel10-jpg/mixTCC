import scipy.io
import torch
import numpy as np
import os
import shutil
from pathlib import Path

def process_cwru_ball_severity():
    # ================= ğŸ”§ åŸºç¡€é…ç½® =================
    CWRU_ROOT = Path(r"D:\Mycode\HAR_Project\CWRU\12k Drive End Bearing Fault Data")
    OUTPUT_DIR = Path(r"D:\Mycode\HAR_Project\data\cwru_ball_severity")
    SEQ_LEN = 1024
    
    # ç±»åˆ«æ˜ å°„
    DATA_MAP = {
        0: (r"Ball\0007", ["B007_0.mat", "B007_1.mat", "B007_2.mat", "B007_3.mat"]),
        1: (r"Ball\0014", ["B014_0.mat", "B014_1.mat", "B014_2.mat", "B014_3.mat"]),
        2: (r"Ball\0021", ["B021_0.mat", "B021_1.mat", "B021_2.mat", "B021_3.mat"]),
    }
    # ===============================================

    print(f"{'='*60}")
    print(f"ğŸš€ CWRU æ•°æ®é‡æ„: 50%è®­ç»ƒæ±  | 25%æµ‹è¯• | 25%éªŒè¯")
    print(f"{'='*60}\n")
    
    if OUTPUT_DIR.exists(): shutil.rmtree(OUTPUT_DIR)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    all_X, all_Y = [], []
    
    # --- 1. è¯»å–æ•°æ® ---
    for label, (sub_folder, files) in DATA_MAP.items():
        folder_path = CWRU_ROOT / sub_folder
        if not folder_path.exists(): continue
        for fname in files:
            fpath = folder_path / fname
            if not fpath.exists(): continue
            try:
                mat = scipy.io.loadmat(str(fpath))
                keys = [k for k in mat.keys() if 'DE_time' in k]
                if not keys: continue
                raw_data = mat[keys[0]].flatten()
                
                # å½’ä¸€åŒ–
                mean_val = np.mean(raw_data)
                std_val = np.std(raw_data)
                if std_val == 0: std_val = 1
                norm_data = (raw_data - mean_val) / std_val
                
                # åˆ‡åˆ†
                n_samples = len(norm_data) // SEQ_LEN
                samples = norm_data[:n_samples*SEQ_LEN].reshape(n_samples, SEQ_LEN, 1)
                labels_arr = np.full(n_samples, label, dtype=int)
                
                all_X.append(torch.tensor(samples, dtype=torch.float32))
                all_Y.append(torch.tensor(labels_arr, dtype=torch.long))
            except Exception as e:
                print(f"   Error {fname}: {e}")

    full_X = torch.cat(all_X, dim=0)
    full_Y = torch.cat(all_Y, dim=0)
    total_samples = len(full_Y)
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}")

    # --- 2. æŒ‰æ¯”ä¾‹åˆ‡åˆ† (50% / 25% / 25%) ---
    # è®­ç»ƒæ± ç”¨äºåç»­ç”Ÿæˆ 1%, 2%... 50% çš„å­é›†
    n_train_pool = int(total_samples * 0.50) 
    n_test = int(total_samples * 0.25)
    # å‰©ä¸‹çš„ç»™éªŒè¯é›†
    
    torch.manual_seed(42) # å›ºå®šç§å­ï¼Œä¿è¯æµ‹è¯•é›†æ°¸è¿œä¸€è‡´
    indices = torch.randperm(total_samples)
    
    idx_train = indices[:n_train_pool]
    idx_test  = indices[n_train_pool : n_train_pool + n_test]
    idx_val   = indices[n_train_pool + n_test :]
    
    print(f"âœ‚ï¸  åˆ’åˆ†è¯¦æƒ…:")
    print(f"   Train Pool (æœ€å¤§å¯ç”¨): {len(idx_train)} (çº¦50%)")
    print(f"   Test Set   (å›ºå®š):     {len(idx_test)} (çº¦25%)")
    print(f"   Val Set    (å›ºå®š):     {len(idx_val)} (çº¦25%)")
    
    splits = {
        "train.pt": idx_train, # è¿™æ˜¯å¤§æ± å­ï¼Œä¹‹åStep1ä¼šä»ä¸­å†åˆ‡åˆ†
        "test.pt":  idx_test,
        "val.pt":   idx_val
    }
    
    for name, idx in splits.items():
        torch.save({"samples": full_X[idx], "labels": full_Y[idx]}, OUTPUT_DIR / name)
        
    print(f"\nğŸ‰ æ•°æ®é‡ç½®å®Œæˆ")

if __name__ == "__main__":
    process_cwru_ball_severity()